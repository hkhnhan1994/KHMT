{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# load and merge file\n",
    "train_label_file = pd.read_csv(\"/kaggle/input/predict-student-performance-from-game-play/train_labels.csv\")\n",
    "train_label_file['q'] = train_label_file.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "train_label_file['session_id'] = train_label_file['session_id'].apply(lambda x: int(x.split('_')[0]))\n",
    "train_label_file.to_csv('/kaggle/working/train_labels_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open('/kaggle/input/predict-student-performance-from-game-play/train.csv', 'r')\n",
    "train_label_file = open('/kaggle/working/train_labels_split.csv', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_header = train_file.readline().strip().split(',')\n",
    "train_label_header = train_label_file.readline().strip().split(',')\n",
    "\n",
    "# Read train file into memory and create a dictionary with ID as the key\n",
    "train_data_dict = {}\n",
    "for train_line in train_file:\n",
    "    train_data = train_line.strip().split(',')\n",
    "    id_value = train_data[0]  # Assuming the 'id' field is the first column\n",
    "    train_data_dict[id_value] = train_data\n",
    "\n",
    "output_file = open('/kaggle/working/merged_data.csv', 'w')\n",
    "output_file.write(','.join(train_header + train_label_header) + '\\n')\n",
    "\n",
    "# Merge train and train_label data using the train_data_dict\n",
    "for train_label_line in train_label_file:\n",
    "    train_label_data = train_label_line.strip().split(',')\n",
    "    id_value = train_label_data[0]  # Assuming the 'id' field is the first column\n",
    "\n",
    "    if id_value in train_data_dict:\n",
    "        train_data = train_data_dict[id_value]\n",
    "        merged_line = ','.join(train_data + train_label_data)\n",
    "        output_file.write(merged_line + '\\n')\n",
    "#         print(f\"Merged line for ID: {id_value}\")\n",
    "    else:\n",
    "        print(f\"No matching train data found for ID: {id_value}\")\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 100000\n",
    "\n",
    "# Initialize a list to store the columns with null records\n",
    "null_columns = []\n",
    "# Iterate over the CSV file in chunks\n",
    "for chunk in pd.read_csv('/kaggle/working/merged_data.csv', chunksize=chunk_size):\n",
    "    # Identify columns with null records in the current chunk\n",
    "    null_cols = chunk.columns[chunk.isnull().any()].tolist()\n",
    "    null_columns.extend(null_cols)\n",
    "\n",
    "# Remove duplicate column names\n",
    "null_columns = list(set(null_columns))\n",
    "\n",
    "# Read the CSV file again, loading only the required columns\n",
    "df = pd.read_csv('/kaggle/working/merged_data.csv', usecols=lambda col: col not in null_columns)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('/kaggle/working/modified_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "input_dim = 11  # Number of input features\n",
    "# Build your neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(input_dim,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Read the CSV file in chunks and split into train/validation sets\n",
    "chunk_size = 100000\n",
    "split_ratio = 0.8\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "train_data_types = {\n",
    "\"session_id\": str,\n",
    "\"index\": np.int32,\n",
    "\"elapsed_time\": np.int32,\n",
    "\"event_name\": str,\n",
    "\"name\": str,\n",
    "\"level\": str,\n",
    "\"room_fqid\": str,\n",
    "\"fullscreen\": np.int32,\n",
    "\"hq\": np.int32,\n",
    "\"music\": np.int32,\n",
    "\"level_group \": str,\n",
    "\"session_id.1\": str,\n",
    "\"correct\": np.int32,\n",
    "\"q\": np.int32,\n",
    "}\n",
    "count =0\n",
    "for chunk in pd.read_csv('/kaggle/working/modified_file.csv', chunksize=chunk_size, dtype= train_data_types):\n",
    "    # Preprocess your data as needed\n",
    "    chunk = chunk.drop('session_id.1', axis=1)\n",
    "    chunk = chunk.drop('q', axis=1)\n",
    "    label_encoder = LabelEncoder()\n",
    "    object_columns = chunk.select_dtypes(include=['object']).columns\n",
    "    for column in object_columns:\n",
    "        chunk[column] = label_encoder.fit_transform(chunk[column])\n",
    "    int_columns = chunk.select_dtypes(include='int64').columns\n",
    "    chunk[int_columns] = chunk[int_columns].astype(np.int32)  # Convert int64 to int32\n",
    "    str_columns = chunk.select_dtypes(include='object').columns\n",
    "    chunk[str_columns] = chunk[str_columns].astype(str)  # Convert object to string\n",
    "\n",
    "    chunk_train, chunk_val = train_test_split(chunk, train_size=split_ratio)\n",
    "    train_data = pd.concat([train_data, chunk_train], ignore_index=True)\n",
    "    val_data = pd.concat([val_data, chunk_val], ignore_index=True)\n",
    "\n",
    "    # Preprocess your data as needed (e.g., scaling, encoding, etc.)\n",
    "    # Split the features and labels\n",
    "    X_train = train_data.drop('correct', axis=1).values\n",
    "    y_train = train_data['correct'].values\n",
    "    X_val = val_data.drop('correct', axis=1).values\n",
    "    y_val = val_data['correct'].values\n",
    "    # Train the model\n",
    "    print(f\"chunk {count}\")\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n",
    "    count=count+1\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_val, y_val)\n",
    "    print('Validation Loss:', loss)\n",
    "    print('Validation Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_data_types = {\n",
    "\"session_id\": str,\n",
    "\"index\": np.int32,\n",
    "\"elapsed_time\": np.int32,\n",
    "\"event_name\": str,\n",
    "\"name\": str,\n",
    "\"level\": str,\n",
    "\"room_fqid\": str,\n",
    "\"fullscreen\": np.int32,\n",
    "\"hq\": np.int32,\n",
    "\"music\": np.int32,\n",
    "\"level_group \": str,\n",
    "\"correct\": np.int32,\n",
    "}\n",
    "test_data = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/test.csv', usecols=[\"session_id\",\"index\",\"elapsed_time\",\"event_name\",\"name\",\"level\",\"room_fqid\",\"fullscreen\",\"hq\",\"music\",\"level_group\"],dtype= test_data_types)\n",
    "\n",
    "# Preprocess the test data using the same label encoder used during training\n",
    "label_encoder = LabelEncoder()\n",
    "object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "for column in object_columns:\n",
    "    test_data[column] = label_encoder.fit_transform(test_data[column])\n",
    "int_columns = test_data.select_dtypes(include='int64').columns\n",
    "test_data[int_columns] = test_data[int_columns].astype(np.int32)  # Convert int64 to int32\n",
    "str_columns = test_data.select_dtypes(include='object').columns\n",
    "test_data[str_columns] = test_data[str_columns].astype(str)  # Convert object to string\n",
    "# Get the test features\n",
    "X_test = test_data.values\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "submission_df = pd.DataFrame({'Prediction': predictions.flatten()})\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"User\": {f\"Hi, I'm having trouble with [specific issue or task]. \\\\\n",
    "    Can you help me troubleshoot or provide guidance on how to resolve it? \"}\n",
    "\n",
    "\"Assistant\": {\"Sure, I'd be happy to assist you. \\\\\n",
    "              Please provide me with some additional information about the problem you're facing. What specific error messages or symptoms are you encountering? Have you tried any troubleshooting steps so far? \n",
    "              The more details you can provide, \\\\\\\n",
    "              the better I can assist you in resolving the issue.\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
